{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.optim as optim\n",
    "from data_loader import SalObjDataset\n",
    "from data_loader import RescaleT\n",
    "from data_loader import RandomCrop\n",
    "from data_loader import ToTensorLab\n",
    "\n",
    "\n",
    "import os\n",
    "from model import BASNet\n",
    "import pytorch_ssim\n",
    "import pytorch_iou\n",
    "# ------- 1. define loss function --------\n",
    "\n",
    "bce_loss = nn.BCELoss(size_average=True)\n",
    "ssim_loss = pytorch_ssim.SSIM(window_size=11,size_average=True)\n",
    "iou_loss = pytorch_iou.IOU(size_average=True)\n",
    "\n",
    "def bce_ssim_loss(pred,target):\n",
    "\n",
    "\tbce_out = bce_loss(pred,target)\n",
    "\tssim_out = 1 - ssim_loss(pred,target)\n",
    "\tiou_out = iou_loss(pred,target)\n",
    "\n",
    "\n",
    "\tloss = bce_out + ssim_out + iou_out\n",
    "\n",
    "\treturn loss\n",
    "\n",
    "def muti_bce_loss_fusion(preds, labels_v):\n",
    "    loss0 = bce_ssim_loss(preds[0], labels_v)\n",
    "    loss=0\n",
    "    for pred in preds:\n",
    "        loss = loss+bce_ssim_loss(pred,labels_v)\n",
    "    return loss0, loss\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    epoch_num = 500\n",
    "    batch_size_train = 8\n",
    "    batch_size_val = 1\n",
    "    train_num = 0\n",
    "    val_num = 0\n",
    "\n",
    "    root=\"./datasets/NEU Surface Defect Dataset/\"\n",
    "    salobj_dataset = SalObjDataset(image_root=os.path.join(root,\"Source Images/\"),\n",
    "                                   gt_root=os.path.join(root,\"Ground truth/\"),\n",
    "                                   transform=transforms.Compose([\n",
    "                                       RescaleT(256),\n",
    "                                       RandomCrop(224),\n",
    "                                       ToTensorLab(flag=0)])\n",
    "                                   )\n",
    "    salobj_dataloader = DataLoader(salobj_dataset, batch_size=batch_size_train, shuffle=True, num_workers=1)\n",
    "    train_num =len(salobj_dataset)\n",
    "    # ------- 3. define model --------\n",
    "\n",
    "    # define the net\n",
    "    net = BASNet(3, 1)\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "\n",
    "    # ------- 4. define optimizer --------\n",
    "    print(\"---define optimizer...\")\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "    # ------- 5. training process --------\n",
    "    print(\"---start training...\")\n",
    "    ite_num = 0\n",
    "    running_loss = 0.0\n",
    "    running_tar_loss = 0.0\n",
    "    ite_num4val = 0\n",
    "\n",
    "    for epoch in range(0, epoch_num):\n",
    "        net.train()\n",
    "\n",
    "        for i, data in enumerate(salobj_dataloader):\n",
    "            ite_num = ite_num + 1\n",
    "            ite_num4val = ite_num4val + 1\n",
    "\n",
    "            inputs, label0= data\n",
    "            inputs = inputs.type(torch.FloatTensor)\n",
    "            label0 = label0.type(torch.FloatTensor)\n",
    "            # label1 = label1.type(torch.FloatTensor)\n",
    "\n",
    "            inputs_v, labels0_v = Variable(inputs.cuda(), requires_grad=False), Variable(label0.cuda(),requires_grad=False)\n",
    "            # y zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs_v)\n",
    "\n",
    "            loss0, loss = muti_bce_loss_fusion(outputs,labels0_v)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # # print statistics\n",
    "            running_loss += loss.item()\n",
    "            running_tar_loss += loss0.item()\n",
    "\n",
    "            # del temporary outputs and loss\n",
    "            del outputs, loss0, loss\n",
    "\n",
    "            print(\"[epoch: %3d/%3d, batch: %5d/%5d, ite: %d] train loss: %3f, tar: %3f \" % (\n",
    "            epoch + 1, epoch_num, (i + 1) * batch_size_train, train_num, ite_num, running_loss / ite_num4val, running_tar_loss / ite_num4val))\n",
    "\n",
    "            if ite_num % 200 == 0:  # save model every 200 iterations\n",
    "\n",
    "                torch.save(net.state_dict(), \"neu_model.pth\" )\n",
    "                running_loss = 0.0\n",
    "                running_tar_loss = 0.0\n",
    "\n",
    "                net.train()  # resume train\n",
    "                ite_num4val = 0\n",
    "\n",
    "    print('-------------Congratulations! Training Done!!!-------------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
